{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import model.utils as utils\n",
    "import model.loader as loader\n",
    "\n",
    "from model.loader import MiniBatchSampler\n",
    "from driver import Driver\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'lol'\n",
    "BATCH_SIZE = 200\n",
    "N_DIM = 32\n",
    "E_DIM = 16\n",
    "T_DIM = 32\n",
    "UNIFORM = False\n",
    "GPU = 0\n",
    "N_LAYER = 1\n",
    "N_HEAD = 4\n",
    "DROPOUT = 0.1\n",
    "N_DEGREE = 10\n",
    "BETA = 0.01\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "MODEL_SAVE_PATH = f'./saved_models/experiment-{DATA}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger = utils.get_logger(\"experiment_\"+DATA+\"_bs\"+str(BATCH_SIZE))\n",
    "\n",
    "utils.set_random_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, g_val, train, val, test, p_classes = loader.load_and_split_data_train_test_val(DATA, N_DIM, E_DIM)\n",
    "\n",
    "train_ngh_finder = loader.get_neighbor_finder(train, g.max_idx, UNIFORM, num_edge_type=g.num_e_type)\n",
    "val_ngh_finder = loader.get_neighbor_finder(g_val, g.max_idx, UNIFORM, num_edge_type=g.num_e_type)\n",
    "test_ngh_finder = loader.get_neighbor_finder(g, g.max_idx, UNIFORM,\n",
    "                                                g.num_e_type)\n",
    "\n",
    "train_batch_sampler = MiniBatchSampler(train.e_type_l, BATCH_SIZE, 'train', p_classes)\n",
    "val_batch_sampler = MiniBatchSampler(val.e_type_l, BATCH_SIZE, 'val', p_classes)\n",
    "test_batch_sampler = MiniBatchSampler(test.e_type_l, BATCH_SIZE, 'test',\n",
    "                                        p_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model.module:Aggregation uses attention model\n",
      "INFO:model.module:Using time encoding\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:{}'.format(GPU)) if GPU != -1 else 'cpu'\n",
    "\n",
    "driver = Driver(g, g_val, train, val, test, p_classes, train_ngh_finder,\n",
    "                val_ngh_finder, test_ngh_finder, train_batch_sampler,\n",
    "                val_batch_sampler, test_batch_sampler, device, T_DIM,\n",
    "                N_LAYER, N_HEAD, DROPOUT, N_DEGREE,\n",
    "                BETA, LEARNING_RATE, MODEL_SAVE_PATH, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [27:21<00:00, 16.41s/it]\n"
     ]
    }
   ],
   "source": [
    "_, _, _, train_acc_l, test_acc_l, loss_l = driver.eval_epochs(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model.module:Aggregation uses attention model\n",
      "INFO:model.module:Using time encoding\n",
      "100%|██████████| 27/27 [07:51<00:00, 17.47s/it]\n",
      " 10%|█         | 1/10 [07:56<1:11:24, 476.05s/it]INFO:model.module:Aggregation uses attention model\n",
      "INFO:model.module:Using time encoding\n",
      "100%|██████████| 27/27 [07:32<00:00, 16.77s/it]\n",
      " 20%|██        | 2/10 [15:34<1:02:04, 465.51s/it]INFO:model.module:Aggregation uses attention model\n",
      "INFO:model.module:Using time encoding\n",
      "100%|██████████| 27/27 [08:21<00:00, 18.56s/it]\n",
      " 30%|███       | 3/10 [24:00<56:30, 484.35s/it]  INFO:model.module:Aggregation uses attention model\n",
      "INFO:model.module:Using time encoding\n",
      "100%|██████████| 27/27 [08:44<00:00, 19.44s/it]\n",
      " 40%|████      | 4/10 [32:51<50:15, 502.60s/it]INFO:model.module:Aggregation uses attention model\n",
      "INFO:model.module:Using time encoding\n",
      "100%|██████████| 27/27 [08:37<00:00, 19.18s/it]\n",
      " 50%|█████     | 5/10 [41:34<42:29, 509.93s/it]INFO:model.module:Aggregation uses attention model\n",
      "INFO:model.module:Using time encoding\n",
      "100%|██████████| 27/27 [08:30<00:00, 18.92s/it]\n",
      " 60%|██████    | 6/10 [50:10<34:08, 512.07s/it]INFO:model.module:Aggregation uses attention model\n",
      "INFO:model.module:Using time encoding\n",
      "100%|██████████| 27/27 [09:04<00:00, 20.15s/it]\n",
      " 70%|███████   | 7/10 [59:19<26:12, 524.22s/it]INFO:model.module:Aggregation uses attention model\n",
      "INFO:model.module:Using time encoding\n",
      "100%|██████████| 27/27 [09:53<00:00, 21.99s/it]\n",
      " 80%|████████  | 8/10 [1:09:19<18:16, 548.23s/it]INFO:model.module:Aggregation uses attention model\n",
      "INFO:model.module:Using time encoding\n",
      "100%|██████████| 27/27 [10:09<00:00, 22.57s/it]\n",
      " 90%|█████████ | 9/10 [1:19:34<09:29, 569.14s/it]INFO:model.module:Aggregation uses attention model\n",
      "INFO:model.module:Using time encoding\n",
      "100%|██████████| 27/27 [10:49<00:00, 24.06s/it]\n",
      "100%|██████████| 10/10 [1:30:31<00:00, 543.11s/it]\n"
     ]
    }
   ],
   "source": [
    "time_steps = loader.get_time_steps(test, p_classes, 10)\n",
    "best_epoch = np.argmax(test_acc_l)\n",
    "\n",
    "window_acc = []\n",
    "window_corr = []\n",
    "for i in tqdm(range(len(time_steps) - 1)):\n",
    "    train, test = loader.split_data_window(g, time_steps[i], time_steps[i + 1])\n",
    "\n",
    "    driver.train = train\n",
    "    driver.test = test\n",
    "    driver.train_ngh_finder = loader.get_neighbor_finder(train, g.max_idx, UNIFORM, num_edge_type=g.num_e_type)\n",
    "    driver.train_batch_sampler = MiniBatchSampler(train.e_type_l, BATCH_SIZE, 'train', p_classes)\n",
    "    driver.test_batch_sampler = MiniBatchSampler(test.e_type_l, BATCH_SIZE, 'test', p_classes)\n",
    "\n",
    "    driver.reset_model()\n",
    "\n",
    "    train_acc_l, loss_l, memory_backup = driver.train_window(best_epoch)\n",
    "    test_acc, corr = driver.test_window(memory_backup)\n",
    "    window_acc.append(test_acc)\n",
    "    window_corr.append(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5926767,\n",
       " 0.57349616,\n",
       " 0.56185085,\n",
       " 0.5527931,\n",
       " 0.52106994,\n",
       " 0.5532411,\n",
       " 0.529576,\n",
       " 0.52678776,\n",
       " 0.52122283,\n",
       " 0.5007017]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.array([x.cpu() for y in window_corr for x in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5480173312126364"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.sum() / len(corr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
